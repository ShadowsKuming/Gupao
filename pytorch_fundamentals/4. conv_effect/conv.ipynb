{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a252bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c30d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "num_classes = 10\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08e519",
   "metadata": {},
   "source": [
    "### construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5169b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),    #[b, 1, 28, 28] -> [b, 16, 28, 28]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                                #[b, 16, 28, 28] -> [b, 16, 14, 14]   \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),    #[b, 16, 14, 14] -> [b, 32, 14, 14]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=5, padding=2),     #[b, 32, 14, 14] -> [b, 32, 14, 14] \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                               #[b, 32, 14, 14] -> [b, 32, 7, 7]\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),   #[b, 32, 7, 7] -> [b, 64, 7, 7]\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Linear(7*7*64, 10)                  #[b, 7*7*64] -> [b, 10]\n",
    "        # self.act = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        # x = self.act(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba018e",
   "metadata": {},
   "source": [
    "### Accuracy as metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c1d5339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    _, predicted = torch.max(y_pred.data, 1)\n",
    "    total = y_true.size(0)\n",
    "    correct = (predicted == y_true).sum().item()\n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871a6b9",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53341f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b35ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 [0/60000 (0%)]\tLoss: 2.303654\tTrain Acc: 7.812%\tVal Acc: 8.920%\n",
      "Epoch: 0 [1600/60000 (11%)]\tLoss: 0.205284\tTrain Acc: 76.856%\tVal Acc: 92.890%\n",
      "Epoch: 0 [3200/60000 (21%)]\tLoss: 0.228525\tTrain Acc: 85.525%\tVal Acc: 96.790%\n",
      "Epoch: 0 [4800/60000 (32%)]\tLoss: 0.211207\tTrain Acc: 89.114%\tVal Acc: 97.430%\n",
      "Epoch: 0 [6400/60000 (43%)]\tLoss: 0.199566\tTrain Acc: 91.077%\tVal Acc: 97.790%\n",
      "Epoch: 0 [8000/60000 (53%)]\tLoss: 0.036057\tTrain Acc: 92.415%\tVal Acc: 97.950%\n",
      "Epoch: 0 [9600/60000 (64%)]\tLoss: 0.033797\tTrain Acc: 93.272%\tVal Acc: 97.740%\n",
      "Epoch: 0 [11200/60000 (75%)]\tLoss: 0.021315\tTrain Acc: 93.926%\tVal Acc: 98.190%\n",
      "Epoch: 0 [12800/60000 (85%)]\tLoss: 0.055106\tTrain Acc: 94.417%\tVal Acc: 98.390%\n",
      "Epoch: 0 [14400/60000 (96%)]\tLoss: 0.089366\tTrain Acc: 94.782%\tVal Acc: 98.250%\n",
      "Epoch: 1 [0/60000 (0%)]\tLoss: 0.088859\tTrain Acc: 96.875%\tVal Acc: 98.470%\n",
      "Epoch: 1 [1600/60000 (11%)]\tLoss: 0.066447\tTrain Acc: 98.530%\tVal Acc: 98.300%\n",
      "Epoch: 1 [3200/60000 (21%)]\tLoss: 0.145767\tTrain Acc: 98.375%\tVal Acc: 98.270%\n",
      "Epoch: 1 [4800/60000 (32%)]\tLoss: 0.151599\tTrain Acc: 98.412%\tVal Acc: 98.790%\n",
      "Epoch: 1 [6400/60000 (43%)]\tLoss: 0.149904\tTrain Acc: 98.367%\tVal Acc: 98.690%\n",
      "Epoch: 1 [8000/60000 (53%)]\tLoss: 0.006261\tTrain Acc: 98.450%\tVal Acc: 98.990%\n",
      "Epoch: 1 [9600/60000 (64%)]\tLoss: 0.002763\tTrain Acc: 98.461%\tVal Acc: 98.690%\n",
      "Epoch: 1 [11200/60000 (75%)]\tLoss: 0.016111\tTrain Acc: 98.475%\tVal Acc: 98.850%\n",
      "Epoch: 1 [12800/60000 (85%)]\tLoss: 0.013650\tTrain Acc: 98.492%\tVal Acc: 98.760%\n",
      "Epoch: 1 [14400/60000 (96%)]\tLoss: 0.029251\tTrain Acc: 98.531%\tVal Acc: 98.660%\n",
      "Epoch: 2 [0/60000 (0%)]\tLoss: 0.003635\tTrain Acc: 100.000%\tVal Acc: 98.810%\n",
      "Epoch: 2 [1600/60000 (11%)]\tLoss: 0.001769\tTrain Acc: 98.824%\tVal Acc: 98.760%\n",
      "Epoch: 2 [3200/60000 (21%)]\tLoss: 0.055019\tTrain Acc: 98.896%\tVal Acc: 98.790%\n",
      "Epoch: 2 [4800/60000 (32%)]\tLoss: 0.039255\tTrain Acc: 98.920%\tVal Acc: 98.880%\n",
      "Epoch: 2 [6400/60000 (43%)]\tLoss: 0.037830\tTrain Acc: 98.944%\tVal Acc: 98.970%\n",
      "Epoch: 2 [8000/60000 (53%)]\tLoss: 0.049427\tTrain Acc: 98.958%\tVal Acc: 98.950%\n",
      "Epoch: 2 [9600/60000 (64%)]\tLoss: 0.020385\tTrain Acc: 98.957%\tVal Acc: 99.200%\n",
      "Epoch: 2 [11200/60000 (75%)]\tLoss: 0.068618\tTrain Acc: 98.961%\tVal Acc: 99.140%\n",
      "Epoch: 2 [12800/60000 (85%)]\tLoss: 0.017199\tTrain Acc: 99.001%\tVal Acc: 99.150%\n",
      "Epoch: 2 [14400/60000 (96%)]\tLoss: 0.002810\tTrain Acc: 99.036%\tVal Acc: 99.010%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "for epoch in range(num_epochs):\n",
    "    train_rights = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = net(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = accuracy(outputs, target)\n",
    "        train_rights.append(correct)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_right = []\n",
    "\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = net(data)\n",
    "                correct = accuracy(outputs, target)\n",
    "                val_right.append(correct)\n",
    "\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            val_r = (sum([tup[0] for tup in val_right]), sum([tup[1] for tup in val_right]))\n",
    "\n",
    "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTrain Acc: {:.3f}%\\tVal Acc: {:.3f}%'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(),\n",
    "                100. * train_r[0] / train_r[1],\n",
    "                100. * val_r[0] / val_r[1]\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4554d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gans-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
